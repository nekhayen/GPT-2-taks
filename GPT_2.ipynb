{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOsJ27s8rZv/iKzJCWk5FqX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nekhayen/GPT-2-taks/blob/main/GPT_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfgwqatTVNDR"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9hnpiaPWXyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09c23433-1950-4999-d438-e7e708ca74f8"
      },
      "source": [
        "print(f\"Detected {torch.cuda.device_count()} PyTorch-compatbile GPU devices.\")\n",
        "print(f\"Name of first GPU device: {torch.cuda.get_device_name(0)}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detected 1 PyTorch-compatbile GPU devices.\n",
            "Name of first GPU device: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW9IlZP1WxOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e17f690a-a803-4da8-81e8-5cbf30be0bf3"
      },
      "source": [
        "#mount google drive with gpt-2\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0USRnpZYJ3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "915b0d21-4088-43bf-997b-fa60a5c7a327"
      },
      "source": [
        "#open cloned transformer-ml package (git clone https://github.com/lopuhin/transformer-lm.git) and install requirements\n",
        "%%shell\n",
        "cd /content/gdrive/My\\ Drive/Colab\\ Notebooks/transformer-lm/\n",
        "pip install -r requirements.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (20.3.0)\n",
            "Collecting json-log-plots==0.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/43/b0de61f8f3352fe6cb62f5eabac8f4ebcb9e00cd2edc2d63b8cc85f4a817/json-log-plots-0.0.1.tar.gz\n",
            "Collecting fire==0.1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/5a/b7/205702f348aab198baecd1d8344a90748cb68f53bdcd1cc30cbc08e47d3e/fire-0.1.3.tar.gz\n",
            "Collecting matplotlib==3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/4f/dd381ecf6c6ab9bcdaa8ea912e866dedc6e696756156d8ecc087e20817e2/matplotlib-3.1.1-cp36-cp36m-manylinux1_x86_64.whl (13.1MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1MB 199kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (1.18.5)\n",
            "Collecting sentencepiece==0.1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/86/aeb647d3ccb924997ea0d05b457d82648a1da57c471688ffbbd69650d9bc/sentencepiece-0.1.8-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 45.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (1.7.0+cu101)\n",
            "Collecting tqdm==4.36.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/c1/bc1dba38b48f4ae3c4428aea669c5e27bd5a7642a74c8348451e0bd8ff86/tqdm-4.36.1-py2.py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.2MB/s \n",
            "\u001b[?25hCollecting json_lines\n",
            "  Downloading https://files.pythonhosted.org/packages/7f/0f/79c96c0d26b276c583484fe8209e5ebbb416a920309568650325f6e1de73/json_lines-0.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from json-log-plots==0.0.1->-r requirements.txt (line 2)) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire==0.1.3->-r requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.1.1->-r requirements.txt (line 4)) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.1.1->-r requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.1.1->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.1.1->-r requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->-r requirements.txt (line 7)) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->-r requirements.txt (line 7)) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->-r requirements.txt (line 7)) (3.7.4.3)\n",
            "Building wheels for collected packages: json-log-plots, fire\n",
            "  Building wheel for json-log-plots (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for json-log-plots: filename=json_log_plots-0.0.1-cp36-none-any.whl size=3320 sha256=6b89bbdca48397fba5b1c9eb910d746826d91494913def3ef1d598f29b96e452\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/06/e0/49b200e17ca0f0bdfb96d124c20e5915db758b6f1a70e34a47\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.1.3-py2.py3-none-any.whl size=49706 sha256=596b0071586af550bcd7057df5e5113c01304d2f239d6b6f93bfc51afb168cfa\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/1a/4d/6b30377c3051e76559d1185c1dbbfff15aed31f87acdd14c22\n",
            "Successfully built json-log-plots fire\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.36.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: json-lines, matplotlib, json-log-plots, fire, sentencepiece, tqdm\n",
            "  Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed fire-0.1.3 json-lines-0.5.0 json-log-plots-0.0.1 matplotlib-3.1.1 sentencepiece-0.1.8 tqdm-4.36.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij0p2KgHZhnT"
      },
      "source": [
        "#add transformer-lm to Python package path\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/Colab Notebooks/transformer-lm/')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH6zMVjen07V"
      },
      "source": [
        "#Initialization of language model wrapper\n",
        "import lm.inference as lmi\n",
        "from pathlib import Path\n",
        "mw = lmi.ModelWrapper.load(Path(\"/content/gdrive/My Drive/Colab Notebooks/pytorch_models/de345-root/\"))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9cKFJVqtCnY"
      },
      "source": [
        "def gpt2_gen(mw, prefix, n_tokens_to_generate=150, top_k=30):\n",
        "  prefix_tokens = mw.tokenize(prefix)# tokenizing the initial text\n",
        "  generated_tokens = mw.generate_tokens(prefix_tokens, n_tokens_to_generate, top_k) # top_k as a sampling method\n",
        "  generated_text = mw.sp_model.DecodePieces(generated_tokens)\n",
        "  return generated_text"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0Jnx7COq3Ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "259867ab-98f0-42e5-e85e-39496edffd96"
      },
      "source": [
        "#Calling gpt2_gen function, passing the text\n",
        "gpt2_gen(mw, \"Capgemini und Audi haben den Start ihres Joint Venture XL2 bekannt gegeben. Nachdem die behördlichen Genehmigungen erteilt worden waren, erfolgte Ende April die Gründung. Das neue Unternehmen wird\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'nun zu dem größten in der Firmengeschichte werden und mit über zwei Milliarden Euro die größte deutsche Unternehmensgruppe vor BASF. Das Joint Venture entsteht nicht aus der gemeinsamen Entwicklungsarbeit für neue Technik in der Forschung _ sondern soll die Arbeit am Markt vorantreiben. Es soll in den neuen Firmen in ganz Europa angesiedelt werden. Die drei neuen Partner sind die Unternehmen Gyricon, Pneumatron, Pt.Sc. und Independence. Das Joint Venture soll das bisherige Kerngeschäft der Firma in den Bereichen Forschung, Entwicklung und Fertigung ausbauen. Die Unternehmensgruppe mit der Marke Gyricon und ihr neues Joint Venture Pneumatron sollen die Basis für die weitere Entwicklung eines integrierten Antriebsstrangs werden. Das Joint Venture wird noch im selben Jahr an den'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}